{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c75e62-116f-4c8c-bf33-93d7c0c0ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d05800-5773-4a5a-914d-f7c9c18595c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# create df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a7e37-e168-450c-a838-acec95272943",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = (\"display\", \"sensors\", \"signal-input-output\", \"device-control\")\n",
    "\n",
    "df_metadata = []\n",
    "for category in categories:\n",
    "    filepath_metadata = f\"../lib_metadata/lib_url_{category}.csv\"\n",
    "    temp_df = pd.read_csv(filepath_metadata, names=[\"id\", \"url1\", \"url2\", \"fullname\", \"repo_desc\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"])\n",
    "    temp_df[\"cat\"] = category\n",
    "    df_metadata.append(\n",
    "        temp_df\n",
    "    )\n",
    "    \n",
    "df_metadata = pd.concat(df_metadata)\n",
    "df_metadata = df_metadata[[\"id\", \"url1\", \"url2\", \"fullname\", \"repo_desc\", \"cat\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5222b8b-85f8-4ce4-9018-d015080711ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068ccc9-ee84-4bf8-8c4a-6fec119dfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.drop_duplicates(subset=\"id\", inplace=True)\n",
    "df_metadata.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ffc53-a48f-4967-b3ed-5bb3972c26b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_metadata = pd.merge(left=df_metadata, right=df_crawler, on=[\"url2\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f05078-16ba-4749-aa88-f02dbe3c0c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_metadata[\"repo_name\"] = df_metadata.fullname.progress_apply(lambda x: x.split(\"/\")[-1])\n",
    "# df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa4acc-3580-482b-a471-be0a90e59bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"protocol_labels.csv\")\n",
    "df_labels.drop_duplicates(subset=[\"git_url\"], inplace=True)\n",
    "df_labels.rename(columns={'git_url':'url1'}, inplace=True)\n",
    "df_labels.drop(columns=[\"cat\", \"repo_name\", \"url\", \"path_repo\"], inplace=True)\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bbb64-03f3-4841-b5de-eb2e2211a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd67c6d-93f4-4f0f-b095-f3c1f3127d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(left=df_metadata, right=df_labels, on=[\"url1\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffbaa22-4d6e-4c45-b1cd-6d2668c793d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9303ee-d04b-48d7-bba2-29c5cc480bf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# download repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5910715-310d-4463-9fab-4cfafa7c6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccfced7-f413-46a5-9713-5ad4f0afa9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_repo(df, target_path):\n",
    "    downloaded = []  \n",
    "    for id_, url1, url2, fullname, repo_desc, cat, _, _, _, _ in tqdm(df.values, total=len(df)):\n",
    "        try:\n",
    "            if url1 not in downloaded:\n",
    "                command = \"git clone \"+ url1\n",
    "                os.chdir(f\"{target_path}\")\n",
    "                os.makedirs(str(id_),  exist_ok = True)\n",
    "                os.chdir(f\"{str(id_)}\")\n",
    "                os.system(command)\n",
    "                os.chdir(\"/data/fix_arduino_project/raw_data\")\n",
    "                time.sleep(1)\n",
    "                downloaded.append(\"success\")\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            downloaded.append(e)\n",
    "    return downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8536857-de6a-46af-8edd-6969393b0164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/data/fix_arduino_project/dataset_raw\")\n",
    "downloaded = download_repo(df_merge, \"libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b37f9-d6b5-401d-a6d7-6e43398a9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['is_downloaded'] = downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11d63e-5bc2-4eaa-a9c3-eaa0fb24f5ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# check protocol label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131dff5d-a496-4313-8c97-ea8e0249caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.is_downloaded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85600433-52f6-42e6-ad72-e5eec5e5518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['has_label'] = df_merge.progress_apply(lambda x: False if np.isnan(x.is_uart) or np.isnan(x.is_spi) or np.isnan(x.is_i2c) or np.isnan(x.is_none) else True, axis=1)\n",
    "df_merge.has_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5632f45-a8ec-42ba-b291-a954ce0676bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge[[\"is_uart\", \"is_spi\", \"is_i2c\", \"is_none\"]] = df_merge[[\"is_uart\", \"is_spi\", \"is_i2c\", \"is_none\"]].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e938ed-084b-402b-a9d2-1afdb9c5a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('is_uart', \"is_spi\", \"is_i2c\", \"is_none\"):\n",
    "    df_merge[col] = df_merge[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54197ba3-1614-4e26-94af-0d16ce11b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026de89-993c-46a5-9269-2db9cdfffcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"url1\": \"url_clone\",\n",
    "    \"url2\": \"url\",\n",
    "    \"repo_desc\": \"desc\"\n",
    "}\n",
    "df_merge.rename(columns=rename_dict, inplace=True)\n",
    "df_merge = df_merge[[\"id\", \"fullname\", \"desc\", \"url\", \"url_clone\", \"is_uart\", \"is_spi\", \"is_i2c\", \"is_none\", \"has_label\", \"is_downloaded\", \"cat\"]]\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe4feb-7d01-42e3-8317-665f77506cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge_cp = df_merge.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a08b68-b50b-4030-8c12-394b0c328e64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# get folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32ef03-6400-4230-8579-a97de427cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"../libraries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f44cdc-ba8d-4343-8e74-739ba5f38b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_name(basepath):\n",
    "    id_to_dirname = {\n",
    "        \"id\": [],\n",
    "        \"dirname\": []\n",
    "    }\n",
    "    directories = os.listdir(basepath)\n",
    "    for directory in directories:\n",
    "        temp_directories = os.listdir(os.path.join(basepath, directory))\n",
    "        assert(len(temp_directories)==1)\n",
    "        id_to_dirname[\"id\"].append(int(directory)) \n",
    "        id_to_dirname[\"dirname\"].append(temp_directories[0])\n",
    "    return id_to_dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2243d79-f7ab-4eb7-8d31-e5668fb89b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_dirname = get_folder_name(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e122a-47d3-466f-b724-f96db7efa37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame.from_dict(id_to_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89c7e1-eceb-406c-9b77-c25bffe678d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08177883-6e50-4525-9544-6672967e7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(left=df_merge, right=temp_df, on=\"id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1984ddf-ff88-4d58-bd07-bd099474c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a1d98-a7fc-41a2-be06-5a1795436932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d1010-025a-4679-a593-e1d9bd8fc824",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# get valid include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11512d4-30fe-4b79-8b05-d1fbb2810723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_appfile(cpp_file):\n",
    "    cpp_file = re.sub(r\"(/\\*.+?(?=\\*/)\\*/)\", \"\", cpp_file, flags=re.DOTALL)\n",
    "    cpp_file = re.sub(r\"(//.+?\\n)\", r\"\\n\", cpp_file, flags=re.DOTALL)\n",
    "    # cpp_file = re.sub(r\"(#.*?\\n)|(#(endif|else))\", r\"\\n\", cpp_file)\n",
    "    cpp_file = cpp_file.split('\\n')\n",
    "    cpp_file = [x.strip() for x in cpp_file if x.strip() != '']\n",
    "    cpp_file = '\\n'.join(cpp_file)\n",
    "    return cpp_file\n",
    "\n",
    "def get_ino_files(path):\n",
    "    dir_list = os.listdir(path)\n",
    "    \n",
    "    codes = []\n",
    "    for dirname in dir_list:\n",
    "        \n",
    "        temp_path = os.path.join(path, dirname)\n",
    "        for root, dirnames, filenames in os.walk(temp_path):\n",
    "            # print(root)\n",
    "            for name in filenames:\n",
    "                \n",
    "                if name.endswith(\".ino\") or name.endswith(\".pde\"):\n",
    "                    filepath = os.path.join(root, name)\n",
    "                    with open(filepath, 'r', errors='ignore') as f:\n",
    "                        code = f.read()\n",
    "                    code = preprocess_appfile(code)\n",
    "                    codes.append({\n",
    "                        'id': int(dirname),\n",
    "                        'path': filepath,\n",
    "                        'code': code,\n",
    "                    })\n",
    "    df = pd.DataFrame(codes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60fde3-0cbb-4388-b8ec-044897cf6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino = get_ino_files(\"libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f628fe7-43f0-4804-986f-54b294b03df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eadeea-44b0-43c2-8bd6-f5c0b21c0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9511c9-d9c1-497f-9402-5d6beb0f7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge[df_merge.id.isin(df_ino.id)].id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71519a9-a0bb-4d2f-acd1-1dd39a57e9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "tree_sitter_path = \"../assets/tree-sitter-cpp/\"\n",
    "\n",
    "Language.build_library(\n",
    "  # Store the library in the `build` directory\n",
    "  \"../assets/build/cpp.so\", \n",
    "   [tree_sitter_path])\n",
    "\n",
    "CP_LANGUAGE = Language('../assets/build/cpp.so', 'cpp')\n",
    "parser = Parser()\n",
    "parser.set_language(CP_LANGUAGE)\n",
    "\n",
    "translator = str.maketrans('', '', '<>\"\\'')\n",
    "\n",
    "### Helper to traverse treesitter output\n",
    "def is_terminal(node):\n",
    "    if len(node.children) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_start_tuple(node):\n",
    "    return node.start_point\n",
    "\n",
    "def get_end_tuple(node):\n",
    "    return node.end_point\n",
    "\n",
    "def get_substring_of_loc(start_tuple, end_tuple, loc_list):\n",
    "    line_number_start, id_begin = start_tuple\n",
    "    line_number_end, id_end = end_tuple\n",
    "    \n",
    "    temp_list = []\n",
    "    if line_number_start != line_number_end:\n",
    "        for idx in range(line_number_start, line_number_end+1):\n",
    "            if idx == line_number_start:\n",
    "                temp_loc = loc_list[idx][id_begin:]\n",
    "            elif idx == line_number_end:\n",
    "                temp_loc = loc_list[idx][:id_end]\n",
    "            else:\n",
    "                temp_loc= loc_list[idx]\n",
    "            \n",
    "            if temp_loc != '':\n",
    "                temp_list.append(temp_loc)\n",
    "    else:\n",
    "        temp_list.append(loc_list[line_number_start][id_begin:id_end])\n",
    "    out = '\\n'.join(temp_list)\n",
    "    return out\n",
    "\n",
    "def fix_punctuation(str_input):\n",
    "    out = str_input.translate(str.maketrans('\"', \"'\", ';'))\n",
    "    return out\n",
    "\n",
    "def get_node_name(node, loc_list):\n",
    "    if is_terminal(node):\n",
    "        start_tuple = get_start_tuple(node)\n",
    "        end_tuple = get_end_tuple(node)\n",
    "        substr = get_substring_of_loc(start_tuple=start_tuple, end_tuple=end_tuple, loc_list=loc_list).strip()\n",
    "        substr = fix_punctuation(substr)\n",
    "        return node.type, substr\n",
    "    else:\n",
    "        return (node.type, '')\n",
    "\n",
    "def resolve_string_literal(node, loc_list):\n",
    "    start_tuple = get_start_tuple(node)\n",
    "    end_tuple = get_end_tuple(node)\n",
    "    substr = get_substring_of_loc(start_tuple=start_tuple, end_tuple=end_tuple, loc_list=loc_list).strip()\n",
    "    substr = fix_punctuation(substr)\n",
    "    return substr\n",
    "\n",
    "def get_substring(node, loc_list):\n",
    "    start_tuple = get_start_tuple(node)\n",
    "    end_tuple = get_end_tuple(node)\n",
    "    return get_substring_of_loc(start_tuple=start_tuple, end_tuple=end_tuple, loc_list=loc_list).strip()\n",
    "###\n",
    "\n",
    "### Traverse the AST\n",
    "def traverse_tree_with_path(tree):\n",
    "    cursor = tree.walk()\n",
    "    current_path = []\n",
    "    current_path.append(cursor.node.type)\n",
    "    reached_root = False\n",
    "    while reached_root == False:\n",
    "        yield cursor.node, current_path\n",
    "\n",
    "        if cursor.goto_first_child():\n",
    "            current_path.append(cursor.node.type)\n",
    "            continue\n",
    "        \n",
    "        if cursor.goto_next_sibling():\n",
    "            if current_path:\n",
    "                current_path.pop(-1)\n",
    "            current_path.append(cursor.node.type)\n",
    "            continue\n",
    "\n",
    "        retracing = True\n",
    "        while retracing:\n",
    "            \n",
    "            if not cursor.goto_parent():\n",
    "                current_path.pop(-1)\n",
    "                retracing = False\n",
    "                reached_root = True\n",
    "                \n",
    "            if current_path:\n",
    "                current_path.pop(-1)\n",
    "                # print(\"a\")\n",
    "                \n",
    "            if cursor.goto_next_sibling():\n",
    "                retracing = False\n",
    "                if current_path:\n",
    "                    current_path.pop(-1)\n",
    "                    \n",
    "                current_path.append(cursor.node.type)\n",
    "###\n",
    "\n",
    "def get_include(code, parser):\n",
    "    output_list = []\n",
    "    query = CP_LANGUAGE.query(\"\"\"\n",
    "    ((preproc_include) @libname)\n",
    "    \"\"\")\n",
    "    tree = parser.parse(bytes(code, \"utf8\"))\n",
    "    query_results = query.captures(tree.root_node)\n",
    "    translator = str.maketrans('', '', '<>\"\\'')\n",
    "\n",
    "    for result in query_results:\n",
    "\n",
    "        ### extract library information\n",
    "        if result[1] in ['libname']:   \n",
    "            \n",
    "            for element, path in traverse_tree_with_path(result[0]):\n",
    "                temp1, temp2 = get_node_name(node=element, loc_list=code.split(\"\\n\"))\n",
    "            \n",
    "                if path[-1] == 'system_lib_string':\n",
    "                    output_list.append(temp2.translate(translator).split(\".\")[0])\n",
    "                \n",
    "                elif path[-1] == 'string_literal':\n",
    "                    temp2 = resolve_string_literal(node=element, loc_list=code.split(\"\\n\"))\n",
    "                    output_list.append(temp2.translate(translator).split(\".\")[0])\n",
    "    \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0d153-77c9-4a2c-8735-78805906492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino['valid_include'] = df_ino.code.progress_apply(lambda x: get_include(x, parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c48fc-7a2c-4b1b-bcad-a6645590cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino[\"len_include\"] = df_ino.valid_include.progress_apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063b7fd-e667-4a22-a39e-98f5c05a0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino = df_ino[df_ino.len_include>0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bee0ef-9588-4dd1-9c39-e5b4e22873b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea721fe0-1c20-4572-aaee-361978a70e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_include_dict = {}\n",
    "for id_, path, code, valid_include, len_include in df_ino.values:\n",
    "    if id_ not in valid_include_dict:\n",
    "        valid_include_dict[id_] = []\n",
    "        \n",
    "    for include in valid_include:\n",
    "        if include not in valid_include_dict[id_] and include not in (\"Wire\", \"SPI\", \"Arduino\", \"SoftwareSerial\"):\n",
    "            valid_include_dict[id_].append(include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd8a66-673b-4640-8b97-1e0c2f01ed96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_include_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa822de6-2456-4dee-a59e-04c2bb3f57bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# get_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a42df-b897-4bd3-93f9-68aee298b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"../libraries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caea625-7c17-40ac-8b9e-89c899459066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_valid_header_filepath(basepath):\n",
    "    valid_headers_dict = {\n",
    "        \"id\": [],\n",
    "        \"headers\": [],\n",
    "        \"cpps\": [],\n",
    "        \"hpps\": [],\n",
    "        \"len_headers\": [],\n",
    "        \"len_cpps\": [],\n",
    "        \"len_hpps\": [],\n",
    "        \"total_len\": [],\n",
    "    }\n",
    "    \n",
    "    directories = os.listdir(basepath)\n",
    "    for directory in directories:\n",
    "        temp_path = os.path.join(basepath, directory)\n",
    "        temp_directories = os.listdir(os.path.join(basepath, directory))\n",
    "        assert(len(temp_directories)==1)\n",
    "        \n",
    "        hw_dirname = os.path.join(temp_path, temp_directories[0])\n",
    "        temp_directories = os.listdir(hw_dirname)\n",
    "        \n",
    "        headers = [os.path.join(hw_dirname, f) for f in temp_directories if os.path.isfile(os.path.join(hw_dirname, f)) and f.endswith(\".h\")]\n",
    "        cpps = [os.path.join(hw_dirname, f) for f in temp_directories if os.path.isfile(os.path.join(hw_dirname, f)) and f.endswith(\".cpp\")]\n",
    "        hpps = [os.path.join(hw_dirname, f) for f in temp_directories if os.path.isfile(os.path.join(hw_dirname, f)) and f.endswith(\".hpp\")]\n",
    "        \n",
    "        # if len(headers)>0 or len(cpps)>0:\n",
    "        # valid_headers_dict[\"id\"].append(int(directory))\n",
    "        # valid_headers_dict[\"headers\"].append(headers)\n",
    "        # valid_headers_dict[\"len_headers\"].append(len(headers))\n",
    "        # valid_headers_dict[\"cpps\"].append(cpps)\n",
    "        # valid_headers_dict[\"len_cpps\"].append(len(cpps))\n",
    "        # valid_headers_dict[\"total_len\"].append(len(cpps)+len(headers))\n",
    "        \n",
    "        if len(headers)==0 or len(cpps)==0:\n",
    "            for temp_directory in temp_directories:\n",
    "                path = os.path.join(hw_dirname, temp_directory)\n",
    "                if temp_directory == \"src\":\n",
    "                    headers = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(\".h\")]\n",
    "                    cpps = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(\".cpp\")]\n",
    "                    hpps = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(\".hpp\")]\n",
    "                    \n",
    "        valid_headers_dict[\"id\"].append(int(directory))\n",
    "        valid_headers_dict[\"headers\"].append(headers)\n",
    "        valid_headers_dict[\"len_headers\"].append(len(headers))\n",
    "        valid_headers_dict[\"cpps\"].append(cpps)\n",
    "        valid_headers_dict[\"len_cpps\"].append(len(cpps))\n",
    "        valid_headers_dict[\"hpps\"].append(cpps)\n",
    "        valid_headers_dict[\"len_hpps\"].append(len(hpps))\n",
    "        valid_headers_dict[\"total_len\"].append(len(cpps)+len(headers)+len(hpps))\n",
    "                \n",
    "    return valid_headers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f659a73c-5b97-49d9-98f6-f018b69f6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge[df_merge.id==409346135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f645d2a-0498-4130-9591-47668e94e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = get_valid_header_filepath(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db188f7-48d1-4196-89b6-b0516913d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717448f2-1950-44e3-9b12-82f02fec936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[temp_df.total_len>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aad1f0-86cc-48b3-b780-7ad80eafcf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.len_cpps.value_counts()[temp_df.len_cpps.value_counts().index<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9507a-9f64-4027-9873-c1823a144666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge.to_csv(\"ckpt_files/df_merge_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0677c-6c4d-44e3-9863-5238433d6d71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097245f0-c6b8-4110-a4e5-e0667411eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(cpp_file):\n",
    "    cpp_file_splitted = cpp_file.split(\"\\n\")\n",
    "    \n",
    "    # seqs = x.seqs\n",
    "    # seqs = seqs.split(\"###\")\n",
    "    \n",
    "    # queries = [x.split(\".\")[-1] for x in seqs]\n",
    "    \n",
    "    # if len(seqs) > 0:\n",
    "    #     obj_identifier = seqs[0].split(\".\")[0]\n",
    "    #     queries.append(obj_identifier)\n",
    "    \n",
    "    tree = parser.parse(bytes(cpp_file, \"utf8\"))\n",
    "    root_node=tree.root_node\n",
    "    \n",
    "    query = CP_LANGUAGE.query(\"\"\"\n",
    "    (translation_unit (function_definition) @function_def)\n",
    "    \"\"\")\n",
    "\n",
    "    captures = query.captures(tree.root_node)\n",
    "    \n",
    "    features = []\n",
    "\n",
    "    for result, _ in captures:\n",
    "        namespace_identifiers = []\n",
    "        found_obj_identifier = False\n",
    "        found_method = False\n",
    "        \n",
    "        for node, path in traverse_tree_with_path(result):\n",
    "            temp1, temp2 = get_node_name(node=node, loc_list=cpp_file_splitted)\n",
    "\n",
    "            # if path[-1] == 'namespace_identifier' and temp2 in queries:\n",
    "                # found_obj_identifier = True\n",
    "                \n",
    "            if len(path) >= 2:\n",
    "            # and found_obj_identifier == True:\n",
    "                \n",
    "                if path[-2] == 'qualified_identifier' and path[-1] == 'identifier':\n",
    "                    # if is_gold:\n",
    "                    #     if temp2 in queries:\n",
    "                    #         found_method = True\n",
    "                    #         break\n",
    "                    # else:\n",
    "                    found_method = True\n",
    "                    break\n",
    "            # print()\n",
    "        if found_method == True:\n",
    "            declaration = get_substring(node=result, loc_list=cpp_file_splitted)\n",
    "            features.append(declaration)\n",
    "        \n",
    "    if len(features) > 0:\n",
    "        return '[SEP]'.join(features)\n",
    "    else:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe83355-7ef4-402e-a9d8-0059fbe8bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_appfile(cpp_file):\n",
    "    cpp_file = re.sub(r\"(/\\*.+?(?=\\*/)\\*/)\", \"\", cpp_file, flags=re.DOTALL)\n",
    "    cpp_file = re.sub(r\"(//.+?\\n)\", r\"\\n\", cpp_file, flags=re.DOTALL)\n",
    "    # cpp_file = re.sub(r\"(#.*?\\n)|(#(endif|else))\", r\"\\n\", cpp_file)\n",
    "    cpp_file = cpp_file.split('\\n')\n",
    "    cpp_file = [x.strip() for x in cpp_file if x.strip() != '']\n",
    "    cpp_file = '\\n'.join(cpp_file)\n",
    "    return cpp_file\n",
    "\n",
    "# def get_features(df):\n",
    "#     df_cp = df.copy()\n",
    "#     features = []\n",
    "#     len_features = []\n",
    "#     for id_, headers, cpps, hpps, len_headers, len_cpps, len_hpps, total_len in df_cp.values:\n",
    "#         temp_list = []\n",
    "#         if len_cpps > 0:\n",
    "#             for path in cpps:\n",
    "#                 with open(path, \"r\", errors='ignore') as f:\n",
    "#                     temp_file = preprocess_appfile(f.read())\n",
    "                    \n",
    "#                     temp_list.append(temp_file)\n",
    "#         elif len_headers > 0:\n",
    "#             for path in headers:\n",
    "#                 with open(path, \"r\", errors='ignore') as f:\n",
    "#                     temp_list.append(preprocess_appfile(f.read()))\n",
    "                    \n",
    "#         elif len_hpps > 0:\n",
    "#             for path in hpps:\n",
    "#                 with open(path, \"r\", errors='ignore') as f:\n",
    "#                     temp_list.append(preprocess_appfile(f.read()))\n",
    "        \n",
    "#         features.append(temp_list)\n",
    "#         len_features.append(len(temp_list))\n",
    "#     df_cp[\"features\"] = features\n",
    "#     df_cp[\"len_features\"] = len_features\n",
    "#     return df_cp\n",
    "\n",
    "def get_features(df):\n",
    "    df_cp = df.copy()\n",
    "    features = []\n",
    "    len_features = []\n",
    "    for id_, headers, cpps, hpps, len_headers, len_cpps, len_hpps, total_len in df_cp.values:\n",
    "        temp_list = []\n",
    "        if len_cpps > 0:\n",
    "            for path in cpps:\n",
    "                with open(path, \"r\", errors='ignore') as f:\n",
    "                    temp_file = preprocess_appfile(f.read())\n",
    "                    features = extract_features(temp_file)\n",
    "                    if features != 'null':\n",
    "                        temp_list.append(features)\n",
    "        elif len_headers > 0:\n",
    "            for path in headers:\n",
    "                with open(path, \"r\", errors='ignore') as f:\n",
    "                    temp_file = preprocess_appfile(f.read())\n",
    "                    features = extract_features(temp_file)\n",
    "                    if features != 'null':\n",
    "                        temp_list.append(features)\n",
    "                    \n",
    "        elif len_hpps > 0:\n",
    "            for path in hpps:\n",
    "                with open(path, \"r\", errors='ignore') as f:\n",
    "                    temp_file = preprocess_appfile(f.read())\n",
    "                    features = extract_features(temp_file)\n",
    "                    if features != 'null':\n",
    "                        temp_list.append(features)\n",
    "        \n",
    "        features.append(temp_list)\n",
    "        len_features.append(len(temp_list))\n",
    "    df_cp[\"features\"] = features\n",
    "    df_cp[\"len_features\"] = len_features\n",
    "    return df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f6272-2c75-4651-a08e-fda2e51cb86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = get_features(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a99faf-8d93-4c28-b43f-ba06f70c1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df[temp_df.len_features > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f93335-6a3e-4c43-9167-d202306dc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df[[\"id\", \"headers\", \"cpps\", \"hpps\", \"features\", \"len_features\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5424749-d641-4e83-a098-12952a01a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(left=df_merge, right=temp_df, on=\"id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013af30-14c9-441c-b8d6-086a72fc010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge.to_csv(\"ckpt_files/df_merge_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef6a02-24a6-4fc7-b3c4-1b5e22fd3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = (\"display\", \"sensors\", \"signal-input-output\", \"device-control\")\n",
    "df_crawler = []\n",
    "for category in categories:\n",
    "    filepath_crawler = f\"lib_crawler/lib_url_{category}.csv\"\n",
    "    temp_df = pd.read_csv(filepath_crawler)\n",
    "    temp_df[\"cat\"] = category\n",
    "    df_crawler.append(\n",
    "        temp_df\n",
    "    )\n",
    "\n",
    "df_crawler = pd.concat(df_crawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb1fb1-546b-491d-a9a4-d1c197b8cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crawler.drop_duplicates(subset=\"url\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e5238-012c-4d7a-aa1b-a04b4a2472d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.rename(columns={'desc':'desc_repo'}, inplace=True)\n",
    "df_crawler.drop(columns=[\"cat\", \"url\", \"sensor\"], inplace=True)\n",
    "df_crawler.rename(columns={'description':'desc_ardulib', 'git_link':'url'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0a812-c712-4083-a379-b7999f19757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(left=df_merge, right=df_crawler, on=\"url\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b3754-86df-4c5c-9472-cfb6413528b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbadb4-2598-4c02-a893-429052a8678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"id\", \"fullname\", \"desc_repo\", \"desc_ardulib\", \"url\", \"url_clone\", \"is_uart\", \"is_spi\", \"is_i2c\", \"is_none\", \"has_label\", \"is_downloaded\", \"cat\", \"dirname\", \"headers\", \"cpps\", \"hpps\", \"features\", \"len_features\"]\n",
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb7acd-edda-47b1-80f8-dd58650e3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge[col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac36e4-505d-46bb-9193-89c686dd9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd974c3f-203a-4d98-a047-2b4a755adcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013d070-7c1b-4d71-8a84-2671a449e474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# get readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b0225-aedf-4c40-a2fd-55689fe59536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_header_filepath(basepath):\n",
    "    valid_headers_dict = {\n",
    "        \"id\": [],\n",
    "        \"readme\": [],\n",
    "        \"len_readme\": [],\n",
    "    }\n",
    "    \n",
    "    directories = os.listdir(basepath)\n",
    "    for directory in directories:\n",
    "        temp_path = os.path.join(basepath, directory)\n",
    "        temp_directories = os.listdir(os.path.join(basepath, directory))\n",
    "        assert(len(temp_directories)==1)\n",
    "        \n",
    "        hw_dirname = os.path.join(temp_path, temp_directories[0])\n",
    "        \n",
    "        headers = [os.path.join(hw_dirname, f) for f in os.listdir(hw_dirname) if os.path.isfile(os.path.join(hw_dirname, f)) and f==\"README.md\"]\n",
    "        temp_list = []\n",
    "        for item in headers:\n",
    "            with open(item, \"r\", errors=\"ignore\") as f:\n",
    "                readme = f.read()\n",
    "                temp_list.append(readme)\n",
    "                \n",
    "        valid_headers_dict[\"id\"].append(int(directory))\n",
    "        valid_headers_dict[\"readme\"].append(temp_list)\n",
    "        valid_headers_dict[\"len_readme\"].append(len(temp_list))\n",
    "        \n",
    "    \n",
    "    return valid_headers_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19c872-a065-44e3-9f3e-af0b17751640",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = get_valid_header_filepath(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca3088-6579-4fc3-bcd1-d8983abb844b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(temp_dict)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe23e6-1e2d-4ec9-a837-b2a4943bc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.drop_duplicates(subset=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f3bac-f501-42dd-ac8c-bfc95118092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.len_readme.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893bafa-6e20-41f6-af32-97c5a12d49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(left=df_merge, right=temp_df, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf38718-10a0-46c0-b1be-000df99c00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34c4be-6385-47d7-a949-5fc029c1c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge.to_csv(\"ckpt_files/df_merge_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16556c69-9060-4606-ade8-550ae2faa056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86bf25-3786-46d8-b922-187779a4d1b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# revise feature 8 october"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a7d7f-ff90-4ce7-b8ef-81deabc6e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c59e83-cde0-4fe8-902b-41fc456a8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ckpt_files/df_merge_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090d4d1-02ed-483b-844d-67906725f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff78b1-664b-4515-9e69-8a4341cb5eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string(x):\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1f74c-54bf-4f05-a117-68359a6ca09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in (\"cpps\", \"headers\", \"hpps\"):\n",
    "    df[colname] = df[colname].progress_apply(lambda x: convert_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7456216-225b-4a0a-89d6-a554a1baa5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(cpp_file):\n",
    "    cpp_file_splitted = cpp_file.split(\"\\n\")\n",
    "    \n",
    "    # seqs = x.seqs\n",
    "    # seqs = seqs.split(\"###\")\n",
    "    \n",
    "    # queries = [x.split(\".\")[-1] for x in seqs]\n",
    "    \n",
    "    # if len(seqs) > 0:\n",
    "    #     obj_identifier = seqs[0].split(\".\")[0]\n",
    "    #     queries.append(obj_identifier)\n",
    "    \n",
    "    tree = parser.parse(bytes(cpp_file, \"utf8\"))\n",
    "    root_node=tree.root_node\n",
    "    \n",
    "    query = CP_LANGUAGE.query(\"\"\"\n",
    "    (translation_unit (function_definition) @function_def)\n",
    "    \"\"\")\n",
    "\n",
    "    captures = query.captures(tree.root_node)\n",
    "    \n",
    "    features = []\n",
    "\n",
    "    for result, _ in captures:\n",
    "        namespace_identifiers = []\n",
    "        found_obj_identifier = False\n",
    "        found_method = False\n",
    "        \n",
    "        for node, path in traverse_tree_with_path(result):\n",
    "            temp1, temp2 = get_node_name(node=node, loc_list=cpp_file_splitted)\n",
    "\n",
    "            # if path[-1] == 'namespace_identifier' and temp2 in queries:\n",
    "                # found_obj_identifier = True\n",
    "                \n",
    "            if len(path) >= 2:\n",
    "            # and found_obj_identifier == True:\n",
    "                \n",
    "                if path[-2] == 'qualified_identifier' and path[-1] == 'identifier':\n",
    "                    # if is_gold:\n",
    "                    #     if temp2 in queries:\n",
    "                    #         found_method = True\n",
    "                    #         break\n",
    "                    # else:\n",
    "                    found_method = True\n",
    "                    break\n",
    "            # print()\n",
    "        if found_method == True:\n",
    "            declaration = get_substring(node=result, loc_list=cpp_file_splitted)\n",
    "            features.append(declaration)\n",
    "        \n",
    "    if len(features) > 0:\n",
    "        return '[SEP]'.join(features)\n",
    "    else:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca98ae5-af96-42c3-8c6d-d505903af975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_appfile(cpp_file):\n",
    "    cpp_file = re.sub(r\"(/\\*.+?(?=\\*/)\\*/)\", \"\", cpp_file, flags=re.DOTALL)\n",
    "    cpp_file = re.sub(r\"(//.+?\\n)\", r\"\\n\", cpp_file, flags=re.DOTALL)\n",
    "    # cpp_file = re.sub(r\"(#.*?\\n)|(#(endif|else))\", r\"\\n\", cpp_file)\n",
    "    cpp_file = cpp_file.split('\\n')\n",
    "    cpp_file = [x.strip() for x in cpp_file if x.strip() != '']\n",
    "    cpp_file = '\\n'.join(cpp_file)\n",
    "    return cpp_file\n",
    "\n",
    "# def get_features(df):\n",
    "#     df_cp = df.copy()\n",
    "#     features = []\n",
    "#     len_features = []\n",
    "#     for id_, headers, cpps, hpps, len_headers, len_cpps, len_hpps, total_len in df_cp.values:\n",
    "#         temp_list = []\n",
    "#         if len_cpps > 0:\n",
    "#             for path in cpps:\n",
    "#                 with open(path, \"r\", errors='ignore') as f:\n",
    "#                     temp_file = preprocess_appfile(f.read())\n",
    "                    \n",
    "#                     temp_list.append(temp_file)\n",
    "#         elif len_headers > 0:\n",
    "#             for path in headers:\n",
    "#                 with open(path, \"r\", errors='ignore') as f:\n",
    "#                     temp_list.append(preprocess_appfile(f.read()))\n",
    "                    \n",
    "#         elif len_hpps > 0:\n",
    "#             for path in hpps:\n",
    "#                 with open(path, \"r\", errors='ignore') as f:\n",
    "#                     temp_list.append(preprocess_appfile(f.read()))\n",
    "        \n",
    "#         features.append(temp_list)\n",
    "#         len_features.append(len(temp_list))\n",
    "#     df_cp[\"features\"] = features\n",
    "#     df_cp[\"len_features\"] = len_features\n",
    "#     return df_cp\n",
    "\n",
    "def get_features(df):\n",
    "    df_cp = df.copy()\n",
    "    features = []\n",
    "    len_features = []\n",
    "    for (id_, fullname, desc_repo, desc_ardulib, url, url_clone,\n",
    "       is_uart, is_spi, is_i2c, is_none, has_label, is_downloaded,\n",
    "       cat, dirname, headers, cpps, hpps, features_, len_features_,\n",
    "       readme, len_readme) in df_cp.values:\n",
    "    # for id_, headers, cpps, hpps, len_headers, len_cpps, len_hpps, total_len in df_cp.values:\n",
    "        temp_list = []\n",
    "        if len(cpps) > 0:\n",
    "            for path in cpps:\n",
    "                with open(path, \"r\", errors='ignore') as f:\n",
    "                    temp_file = preprocess_appfile(f.read())\n",
    "                    temp_features = extract_features(temp_file)\n",
    "                    if temp_features != 'null':\n",
    "                        temp_list.append(temp_features)\n",
    "        elif len(headers) > 0:\n",
    "            for path in headers:\n",
    "                with open(path, \"r\", errors='ignore') as f:\n",
    "                    temp_file = preprocess_appfile(f.read())\n",
    "                    temp_features = extract_features(temp_file)\n",
    "                    if temp_features != 'null':\n",
    "                        temp_list.append(temp_features)\n",
    "                    \n",
    "        elif len(hpps) > 0:\n",
    "            for path in hpps:\n",
    "                with open(path, \"r\", errors='ignore') as f:\n",
    "                    temp_file = preprocess_appfile(f.read())\n",
    "                    temp_features = extract_features(temp_file)\n",
    "                    if temp_features != 'null':\n",
    "                        temp_list.append(temp_features)\n",
    "        \n",
    "        features.append(temp_list)\n",
    "        len_features.append(len(temp_list))\n",
    "    df_cp[\"features\"] = features\n",
    "    df_cp[\"len_features\"] = len_features\n",
    "    return df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb3ea8-0b6c-4701-97cc-4bb2d36117bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = get_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92b392-ed45-4df1-b441-57e301e5b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc394-b524-4ce5-b5e7-eddc74234f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv(\"ckpt_files/df_merge_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38759039-6f91-4e93-8a3d-77e9ce059ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# exclude not found feature 31 oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fbfde-9755-4167-b0cb-12a113463a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../ckpt_files/df_merge_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275f6d9-33c3-4b0e-8b82-0eb41ea82d2a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_string(x):\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7014ec2-9320-40bd-a9c7-132a05ebd3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features'] = df.features.progress_apply(lambda x: convert_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54155b50-379f-41b9-81ef-93b7e6fb3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc578f-954b-4a09-bfdc-3e04313ab3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.len_features > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89637ff5-7d55-4fc5-bec4-444a10c14b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5fd00-70fd-4a80-8122-298a680ed2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_mapping = pd.read_csv(\"../generate_constructor_mapping/lib_to_constructor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70499d41-fef1-4941-a065-0ca4b99b429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e871ae5-f70d-433c-9218-fbe91c2a27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.id.isin(constructor_mapping.id)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53a202-ca45-460f-aa19-6055811159a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['url_clone', 'is_uart', 'is_spi', 'is_uart', 'is_i2c', 'is_none', 'is_downloaded', 'headers', 'cpps', 'hpps', 'len_features', 'readme', 'len_readme', 'has_label', 'fullname'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432c6a3-b331-4269-84eb-70a90b1fa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id', 'dirname', 'desc_repo', 'desc_ardulib', 'url', 'cat', 'features']].copy()\n",
    "df.rename(columns={'dirname':'library'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa3400-9155-48fb-8576-04793f531648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"null\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a6264-5cc6-4d5b-b4e5-e4c78df9b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features'] = df.features.progress_apply(lambda x: \"###\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcada16-7eb4-4f28-86d2-6071c1d4cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5035e8-c4b2-4f50-9cb4-60b8acf4a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lib_to_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acc795-4a35-42b6-85bf-386a080c670e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
