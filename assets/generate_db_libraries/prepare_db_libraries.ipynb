{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e6c1e-8cbf-433e-b784-4c65d69f0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from tree_sitter import Language, Parser\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b763808-9732-4f6f-8428-85d2bb732f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_sitter_path = \"../assets/tree-sitter-cpp/\"\n",
    "\n",
    "Language.build_library(\n",
    "  # Store the library in the `build` directory\n",
    "  \"../assets/build/cpp.so\", \n",
    "   [tree_sitter_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb4be9-b276-4494-bb03-f973177428b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CP_LANGUAGE = Language('../tree_sitter/cpp.so', 'cpp')\n",
    "parser = Parser()\n",
    "parser.set_language(CP_LANGUAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d5152-8755-410d-b559-4d7b48ee18f4",
   "metadata": {},
   "source": [
    "# get header files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca1d76-838c-4604-a703-78f255d3391b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_appfile(cpp_file):\n",
    "    cpp_file = re.sub(r\"(/\\*.+?(?=\\*/)\\*/)\", \"\", cpp_file, flags=re.DOTALL)\n",
    "    cpp_file = re.sub(r\"(//.+?\\n)\", r\"\\n\", cpp_file, flags=re.DOTALL)\n",
    "    cpp_file = re.sub(r\"(#.*?\\n)|(#(endif|else))\", r\"\\n\", cpp_file)\n",
    "    cpp_file = cpp_file.split('\\n')\n",
    "    cpp_file = [x.strip() for x in cpp_file if x.strip() != '']\n",
    "    cpp_file = '\\n'.join(cpp_file)\n",
    "    return cpp_file\n",
    "\n",
    "def get_h_files(path):\n",
    "    dir_list = os.listdir(path)\n",
    "    \n",
    "    codes = []\n",
    "    for id_ in dir_list:\n",
    "        temp_path = os.path.join(path, id_)\n",
    "        \n",
    "        for root, dirnames, filenames in os.walk(temp_path):\n",
    "            \n",
    "            for name in filenames:    \n",
    "                if name.endswith(\".h\"):\n",
    "                    filepath = os.path.join(root, name)\n",
    "                    library = root.split(\"/\")[3]\n",
    "                    with open(filepath, 'r', errors='ignore') as f:\n",
    "                        code = f.read()\n",
    "                    code = preprocess_appfile(code)\n",
    "                    codes.append({\n",
    "                        'id': id_,\n",
    "                        'library': library,\n",
    "                        'path': filepath,\n",
    "                        'code': code,\n",
    "                    })\n",
    "    df = pd.DataFrame(codes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4375f8-61f0-4c96-a18a-c071fc2db2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_h_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151eb65-2ea1-4633-b4eb-34a5dc8b1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ffc20-a9da-4737-ad3d-4fe8974daf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = get_h_files(\"../ArduinoCore-avr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6a3ac-c922-4e8b-9187-a310efac0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378ba09-e98f-4da4-800a-9d43de6a402c",
   "metadata": {},
   "source": [
    "# helper traverse the AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae310ad-af71-40ff-a65c-1e65f212a855",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', '<>\"\\'')\n",
    "\n",
    "### Helper to traverse treesitter output\n",
    "def is_terminal(node):\n",
    "    if len(node.children) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_start_tuple(node):\n",
    "    return node.start_point\n",
    "\n",
    "def get_end_tuple(node):\n",
    "    return node.end_point\n",
    "\n",
    "def get_substring_of_loc(start_tuple, end_tuple, loc_list):\n",
    "    line_number_start, id_begin = start_tuple\n",
    "    line_number_end, id_end = end_tuple\n",
    "    \n",
    "    temp_list = []\n",
    "    if line_number_start != line_number_end:\n",
    "        for idx in range(line_number_start, line_number_end+1):\n",
    "            if idx == line_number_start:\n",
    "                temp_loc = loc_list[idx][id_begin:]\n",
    "            elif idx == line_number_end:\n",
    "                temp_loc = loc_list[idx][:id_end]\n",
    "            else:\n",
    "                temp_loc= loc_list[idx]\n",
    "            \n",
    "            if temp_loc != '':\n",
    "                temp_list.append(temp_loc)\n",
    "    else:\n",
    "        temp_list.append(loc_list[line_number_start][id_begin:id_end])\n",
    "    out = '\\n'.join(temp_list)\n",
    "    return out\n",
    "\n",
    "def fix_punctuation(str_input):\n",
    "    out = str_input.translate(str.maketrans('\"', \"'\", ';'))\n",
    "    return out\n",
    "\n",
    "def get_node_name(node, loc_list):\n",
    "    if is_terminal(node):\n",
    "        start_tuple = get_start_tuple(node)\n",
    "        end_tuple = get_end_tuple(node)\n",
    "        substr = get_substring_of_loc(start_tuple=start_tuple, end_tuple=end_tuple, loc_list=loc_list).strip()\n",
    "        substr = fix_punctuation(substr)\n",
    "        return node.type, substr\n",
    "    else:\n",
    "        return (node.type, '')\n",
    "\n",
    "def resolve_string_literal(node, loc_list):\n",
    "    start_tuple = get_start_tuple(node)\n",
    "    end_tuple = get_end_tuple(node)\n",
    "    substr = get_substring_of_loc(start_tuple=start_tuple, end_tuple=end_tuple, loc_list=loc_list).strip()\n",
    "    substr = fix_punctuation(substr)\n",
    "    return substr\n",
    "\n",
    "def get_substring(node, loc_list):\n",
    "    start_tuple = get_start_tuple(node)\n",
    "    end_tuple = get_end_tuple(node)\n",
    "    return get_substring_of_loc(start_tuple=start_tuple, end_tuple=end_tuple, loc_list=loc_list).strip()\n",
    "###\n",
    "\n",
    "### Traverse the AST\n",
    "def traverse_tree_with_path(tree):\n",
    "    cursor = tree.walk()\n",
    "    current_path = []\n",
    "    current_path.append(cursor.node.type)\n",
    "    reached_root = False\n",
    "    while reached_root == False:\n",
    "        yield cursor.node, current_path\n",
    "\n",
    "        if cursor.goto_first_child():\n",
    "            current_path.append(cursor.node.type)\n",
    "            continue\n",
    "        \n",
    "        if cursor.goto_next_sibling():\n",
    "            if current_path:\n",
    "                current_path.pop(-1)\n",
    "            current_path.append(cursor.node.type)\n",
    "            continue\n",
    "\n",
    "        retracing = True\n",
    "        while retracing:\n",
    "            \n",
    "            if not cursor.goto_parent():\n",
    "                current_path.pop(-1)\n",
    "                retracing = False\n",
    "                reached_root = True\n",
    "                \n",
    "            if current_path:\n",
    "                current_path.pop(-1)\n",
    "                # print(\"a\")\n",
    "                \n",
    "            if cursor.goto_next_sibling():\n",
    "                retracing = False\n",
    "                if current_path:\n",
    "                    current_path.pop(-1)\n",
    "                    \n",
    "                current_path.append(cursor.node.type)\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5e709-4a3e-4921-ab32-0dc3c341c827",
   "metadata": {},
   "source": [
    "# process header files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c2be7-47c4-45fb-b139-c5ce49bac4d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_constructor(code):\n",
    "    try:\n",
    "        classes = []\n",
    "        query = CP_LANGUAGE.query(\"\"\"\n",
    "        (class_specifier (type_identifier) @constructor)\n",
    "        \"\"\")\n",
    "        tree = parser.parse(bytes(code, \"utf8\"))\n",
    "        query_results = query.captures(tree.root_node)\n",
    "        \n",
    "        for node, _ in query_results:\n",
    "            temp1, temp2 = get_node_name(node=node, loc_list=code.split(\"\\n\"))\n",
    "            classes.append(temp2)\n",
    "        \n",
    "        if len(classes) > 0:\n",
    "            return ' '.join(classes)\n",
    "        else: \n",
    "            return 'null'\n",
    "    \n",
    "    except Exception as e:\n",
    "        return 'null'\n",
    "    \n",
    "def get_methods(code):\n",
    "    try:\n",
    "        methods_dict = {}\n",
    "        query = CP_LANGUAGE.query(\"\"\"\n",
    "        ((class_specifier) @constructor)\n",
    "        \"\"\")\n",
    "        tree = parser.parse(bytes(code, \"utf8\"))\n",
    "        query_results = query.captures(tree.root_node)\n",
    "        is_public = False\n",
    "        temp_exp = ''\n",
    "        \n",
    "        for item, _ in query_results:\n",
    "            methods = []\n",
    "            \n",
    "            for node, path in traverse_tree_with_path(item):\n",
    "                temp1, temp2 = get_node_name(node=node, loc_list=code.split(\"\\n\"))\n",
    "                \n",
    "                if path[-1] == 'public':\n",
    "                    is_public = True\n",
    "\n",
    "                elif path[-1] == 'private':\n",
    "                    is_public = False\n",
    "\n",
    "                if len(path)>=2:\n",
    "                    if path[-2] == 'class_specifier' and path[-1] == 'type_identifier':\n",
    "                        classname = temp2\n",
    "                    \n",
    "                    if is_public:\n",
    "                        \n",
    "                        if path[-1] in ('function_definition'):\n",
    "                            temp_exp = get_substring(node, code.split(\"\\n\"))\n",
    "                            methods.append(temp_exp)\n",
    "                        elif path[-1] == 'field_declaration':\n",
    "                            temp_exp = get_substring(node, code.split(\"\\n\"))\n",
    "\n",
    "                        if path[-1] == 'function_declarator' and temp_exp != '':\n",
    "                            methods.append(temp_exp)\n",
    "                        elif path[-1] == ';':\n",
    "                            temp_exp = ''\n",
    "            \n",
    "            methods_dict[classname] = methods.copy()\n",
    "        \n",
    "        if len(methods_dict) > 0:\n",
    "            return methods_dict\n",
    "        else:\n",
    "            return 'null'\n",
    "    \n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        return 'null'\n",
    "    \n",
    "def process_methods(methods_dict):\n",
    "    try:\n",
    "        new_methods_dict = {}\n",
    "        # new_methods = []\n",
    "\n",
    "        for constructor, methods in methods_dict.items():\n",
    "            new_methods_dict[constructor] = []\n",
    "\n",
    "            for method in methods:\n",
    "                tree = parser.parse(bytes(method, \"utf8\"))\n",
    "\n",
    "                for node, path in traverse_tree_with_path(tree.root_node):\n",
    "                    temp1, temp2 = get_node_name(node=node, loc_list=method.split(\"\\n\"))\n",
    "\n",
    "                    if len(path) >= 2:\n",
    "                        if path[-2] == 'function_declarator' and path[-1] == 'identifier':\n",
    "                            new_methods_dict[constructor].append(temp2)\n",
    "\n",
    "            new_methods_dict[constructor] = set(new_methods_dict[constructor])\n",
    "        \n",
    "        if len(new_methods_dict)> 0:\n",
    "            return new_methods_dict\n",
    "        \n",
    "        else:\n",
    "            return \"null\"\n",
    "        \n",
    "    except:\n",
    "        return 'null'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c20e53-2f47-4b55-ab06-71f4361c91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df.code.str.split().str.len()\n",
    "df = df[df.len <= 5000].copy()\n",
    "df['constructor'] = df.code.progress_apply(lambda x: get_constructor(x)) \n",
    "df['methods'] = df.code.progress_apply(lambda x: get_methods(x)) \n",
    "df['processed_methods'] = df.methods.progress_apply(lambda x: process_methods(x)) \n",
    "df['fname'] = df.path.progress_apply(lambda x: x.split(\"/\")[-1].replace(\".h\", \"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf531b26-ae14-46c8-92e9-f16fe52df535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a21c9e-7b6a-48ca-af55-bbb49cabc15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_core['len'] = df_core.code.str.split().str.len()\n",
    "df_core['constructor'] = df_core.code.progress_apply(lambda x: get_constructor(x)) \n",
    "df_core['methods'] = df_core.code.progress_apply(lambda x: get_methods(x)) \n",
    "df_core['processed_methods'] = df_core.methods.progress_apply(lambda x: process_methods(x))\n",
    "df_core['fname'] = df_core.path.progress_apply(lambda x: x.split(\"/\")[-1].replace(\".h\", \"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39cbfdb-6b57-4c50-8182-c1f1719a6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3909d49-0e18-4806-8750-224f0412cc32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# resolve parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889f78d-e199-4915-9852-b37c6c632f9e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_parent_class(code):\n",
    "    try:\n",
    "        parents_dict = {}\n",
    "        query = CP_LANGUAGE.query(\"\"\"\n",
    "        ((class_specifier) @constructor)\n",
    "        \"\"\")\n",
    "        tree = parser.parse(bytes(code, \"utf8\"))\n",
    "        query_results = query.captures(tree.root_node)\n",
    "        classname = ''\n",
    "        \n",
    "        for item, _ in query_results:\n",
    "            parents = []\n",
    "            \n",
    "            for node, path in traverse_tree_with_path(item):\n",
    "                temp1, temp2 = get_node_name(node=node, loc_list=code.split(\"\\n\"))\n",
    "\n",
    "                if path == ['class_specifier', 'type_identifier']:\n",
    "                    classname = temp2\n",
    "\n",
    "                elif 'base_class_clause' in path and path[-1] == 'type_identifier':\n",
    "                    parents.append(temp2)\n",
    "\n",
    "                elif len(parents) > 0 and 'base_class_clause' not in path:\n",
    "                    parents_dict[classname] = parents.copy()\n",
    "                    classname = ''\n",
    "                    parents = []\n",
    "                    break\n",
    "\n",
    "        if len(parents_dict) > 0:\n",
    "            return parents_dict\n",
    "        else: \n",
    "            return 'null'\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'null'\n",
    "    \n",
    "def get_all_core_method_dict_from_repo(df, is_resolved=False):\n",
    "    df_cp = deepcopy(df)\n",
    "    df_cp = df_cp[(df_cp.methods!='null')].copy()\n",
    "    methods_all = {}\n",
    "    \n",
    "    if is_resolved:\n",
    "        \n",
    "        for id_, repo_name, path, code, methods, constructor, fname in df_cp.values:\n",
    "\n",
    "            if type(methods) == dict:\n",
    "\n",
    "                for key, method_list in methods.items():\n",
    "\n",
    "                    if key not in methods_all:\n",
    "                        methods_all[key] = []\n",
    "\n",
    "                    for method in method_list:\n",
    "                        methods_all[key].append(method)\n",
    "\n",
    "                    methods_all[key] = set(methods_all[key])\n",
    "    else:\n",
    "         for id_, repo_name, path, code, _, constructor, methods, processed_methods, fname, parents in df_cp.values:\n",
    "\n",
    "            if type(processed_methods) == dict:\n",
    "\n",
    "                for key, method_list in processed_methods.items():\n",
    "\n",
    "                    if key not in methods_all:\n",
    "                        methods_all[key] = []\n",
    "\n",
    "                    for method in method_list:\n",
    "                        methods_all[key].append(method)\n",
    "\n",
    "                    methods_all[key] = set(methods_all[key])\n",
    "        \n",
    "    return methods_all\n",
    "\n",
    "def resolve_inheritance_core(df, is_resolved = False):\n",
    "    df_cp = df.copy()\n",
    "    df_list = []\n",
    "    \n",
    "    for id_, repo_name, path, code, _, constructor, methods, processed_methods, fname, parents in tqdm(df_cp.values, total=len(df_cp)):\n",
    "        class_to_methods_all = get_all_core_method_dict_from_repo(df, is_resolved)\n",
    "        class_to_parents_all = get_all_parent_dict_from_repo(df, repo_name)\n",
    "        method_dict = deepcopy(processed_methods)\n",
    "        resolved_method_dict = {}\n",
    "        \n",
    "        if type(parents) == dict:\n",
    "            resolved_method_dict =  resolve_parent_class_iter(parents, class_to_parents_all, class_to_methods_all)\n",
    "\n",
    "        if len(resolved_method_dict) > 0 :\n",
    "            \n",
    "            for classname, method_list in resolved_method_dict.items():\n",
    "                resolved_method_dict[classname] = set(method_list)\n",
    "            \n",
    "            if type(method_dict) == str:\n",
    "                method_dict = {}\n",
    "            \n",
    "            for classname, method_set in resolved_method_dict.items():\n",
    "                # method_dict.pop(classname, None)\n",
    "                # method_dict[classname] = resolved_method_dict.get(classname)\n",
    "                if classname not in method_dict:\n",
    "                    method_dict[classname] = set()\n",
    "                    \n",
    "                method_dict[classname] = method_dict[classname].union(method_set)\n",
    "\n",
    "                \n",
    "        temp_dict = {'id': id_,\n",
    "                    'repo_name': repo_name,\n",
    "                    'path': path,\n",
    "                    'code': code,\n",
    "                    'methods': method_dict,\n",
    "                    'constructor': constructor,\n",
    "                    'fname': fname}    \n",
    "        \n",
    "        df_list.append(temp_dict)\n",
    "    \n",
    "    df_out = pd.DataFrame(df_list)\n",
    "    return df_out\n",
    "\n",
    "def get_all_method_dict_from_repo(df, repo_name):\n",
    "    df_cp = deepcopy(df)\n",
    "    df_cp = df_cp[(df_cp.library==repo_name) & (df_cp.processed_methods!='null')].copy()\n",
    "    methods_all = {}\n",
    "\n",
    "    for id_, repo_name, path, code, _, constructor, methods, processed_methods, fname, parents in df_cp.values:\n",
    "        \n",
    "        if type(processed_methods) == dict:\n",
    "            \n",
    "            for key, method_set in processed_methods.items():\n",
    "\n",
    "                if key not in methods_all:\n",
    "                    methods_all[key] = set()\n",
    "                \n",
    "                methods_all[key] = methods_all[key].union(method_set)\n",
    "                   \n",
    "    return methods_all\n",
    "\n",
    "def get_all_parent_dict_from_repo(df, repo_name, is_core=False):\n",
    "    df_cp = deepcopy(df)\n",
    "    \n",
    "    if is_core:\n",
    "        df_cp = df_cp[(df_cp.processed_methods!='null')].copy()\n",
    "    \n",
    "    else:\n",
    "        df_cp = df_cp[(df_cp.library==repo_name) & (df_cp.processed_methods!='null')].copy()\n",
    "\n",
    "    parents_all = {}\n",
    "    \n",
    "    for id_, repo_name, path, code, _, constructor, methods, processed_methods, fname, parents in df_cp.values:\n",
    "        \n",
    "        if type(parents) == dict:\n",
    "            parents_all.update(parents)\n",
    "        \n",
    "    new_parents_all = {}\n",
    "    \n",
    "    for key, val in parents_all.items():\n",
    "        new_parents_all[key] = []\n",
    "        \n",
    "        for temp_val in val:\n",
    "            \n",
    "            if temp_val != key:\n",
    "                new_parents_all[key].append(temp_val)\n",
    "        \n",
    "    return new_parents_all\n",
    "            \n",
    "def resolve_inheritance(df, class_to_methods_all_core):\n",
    "    df_cp = df.copy()\n",
    "    df_list = []\n",
    "    \n",
    "    for id_, repo_name, path, code, _, constructor, methods, processed_methods, fname, parents in tqdm(df_cp.values, total=len(df_cp)):\n",
    "        class_to_methods_all = get_all_method_dict_from_repo(df, repo_name)\n",
    "        # print(class_to_methods_all)\n",
    "        for classname, method_set in class_to_methods_all_core.items():\n",
    "            \n",
    "            if classname not in class_to_methods_all:\n",
    "                class_to_methods_all[classname] = set()\n",
    "            \n",
    "            class_to_methods_all[classname] = class_to_methods_all[classname].union(method_set)\n",
    "        \n",
    "        class_to_parents_all = get_all_parent_dict_from_repo(df, repo_name)\n",
    "        method_dict = deepcopy(processed_methods)\n",
    "        resolved_method_dict = {}\n",
    "        \n",
    "        if type(parents) == dict:\n",
    "            resolved_method_dict =  resolve_parent_class_iter(parents, class_to_parents_all, class_to_methods_all)\n",
    "\n",
    "        if len(resolved_method_dict) > 0 :\n",
    "            \n",
    "            for classname, method_list in resolved_method_dict.items():\n",
    "                resolved_method_dict[classname] = set(method_list)\n",
    "            \n",
    "            if type(method_dict) == str:\n",
    "                method_dict = {}\n",
    "            \n",
    "            for classname, method_set in resolved_method_dict.items():\n",
    "                # method_dict.pop(classname, None)\n",
    "                \n",
    "                if classname not in method_dict:\n",
    "                    method_dict[classname] = set()\n",
    "                    \n",
    "                method_dict[classname] = method_dict[classname].union(method_set) \n",
    "\n",
    "                \n",
    "        temp_dict = {'id': id_,\n",
    "                    'repo_name': repo_name,\n",
    "                    'path': path,\n",
    "                    'code': code,\n",
    "                    'methods': method_dict,\n",
    "                    'methods_exp': methods,\n",
    "                    'constructor': constructor,\n",
    "                    'fname': fname}    \n",
    "        \n",
    "        df_list.append(temp_dict)\n",
    "    \n",
    "    df_out = pd.DataFrame(df_list)\n",
    "    return df_out \n",
    "\n",
    "def resolve_parent_class_iter(parent_dict, all_parent_dict, all_method_dict):\n",
    "    all_parent_dict_cp = deepcopy(all_parent_dict)\n",
    "\n",
    "    all_method_dict_cp = deepcopy(all_method_dict)\n",
    "    \n",
    "    method_dict = {}\n",
    "    \n",
    "    \n",
    "    for classname, parent_classname_list in parent_dict.items():\n",
    "        temp_method_list = list(all_method_dict_cp.get(classname, {}))\n",
    "        \n",
    "        if classname not in method_dict:\n",
    "            method_dict[classname] = []\n",
    "        # print(method_dict)\n",
    "        for method in temp_method_list:\n",
    "            \n",
    "            if  method not in method_dict[classname]: \n",
    "                \n",
    "                method_dict[classname].append(method)\n",
    "        \n",
    "        parent_methods = resolve_parent_class(parent_dict, all_parent_dict, all_method_dict)\n",
    "        # print(method_dict)\n",
    "        for method in parent_methods:\n",
    "\n",
    "            if method not in method_dict[classname]:\n",
    "                method_dict[classname].append(method)\n",
    "                \n",
    "    return method_dict\n",
    "\n",
    "def resolve_parent_class(parent_dict, all_parent_dict, all_method_dict):\n",
    "    all_parent_dict_cp = deepcopy(all_parent_dict)\n",
    "\n",
    "    all_method_dict_cp = deepcopy(all_method_dict)\n",
    "\n",
    "    parent_dict_cp = deepcopy(parent_dict)\n",
    "    \n",
    "    output_list = []\n",
    "    \n",
    "    for classname, parent_classname_list in parent_dict.items():\n",
    "\n",
    "        for parent_classname in parent_classname_list:\n",
    "            parent_methods = all_method_dict_cp.get(parent_classname, {})\n",
    "            \n",
    "            for method in parent_methods:\n",
    "                \n",
    "                if method != classname:\n",
    "                    output_list.append(method)\n",
    "\n",
    "            parent_parent_classname_list = all_parent_dict_cp.get(parent_classname, [])\n",
    "            temp_parent_dict = {parent_classname: parent_parent_classname_list}\n",
    "            temp_methods = resolve_parent_class(temp_parent_dict, all_parent_dict, all_method_dict)\n",
    "            \n",
    "            for method in temp_methods:\n",
    "                output_list.append(method)\n",
    "                \n",
    "    return output_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c7635-f5ee-4fbc-b5b4-94531ca912b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parents'] = df.code.progress_apply(lambda x: get_parent_class(x))\n",
    "df_cp = deepcopy(df)\n",
    "\n",
    "df_core['parents'] = df_core.code.progress_apply(lambda x: get_parent_class(x))\n",
    "df_core_cp = deepcopy(df_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6a0e1-42d2-4be0-a1f0-1b4e59517165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core_resolved = resolve_inheritance_core(df_core_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ae1a5-5232-4ecc-b839-db6c4ae29cfd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_method_dict = get_all_core_method_dict_from_repo(df_core_cp)\n",
    "# test_parent_dict = get_all_parent_dict_from_repo(df_core_cp, \"UDP\", True)\n",
    "# resolve_parent_class_iter({\"UDP\": [\"Stream\"]}, test_parent_dict, test_method_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a7eb5-3b0c-470c-95e5-72d6439144b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_core_cp[(df_core_cp.fname==\"Print\") & (df_core_cp.processed_methods!='null')].iloc[0].processed_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c29d73-9222-4ac5-afa1-6bc7da60a1bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_core_cp[(df_core_cp.fname==\"Stream\") & (df_core_cp.processed_methods!='null')].iloc[0].processed_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fd3bd-b229-4fa2-b0e8-8225e0c84a3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_core_cp[(df_core_cp.fname==\"Udp\") & (df_core_cp.processed_methods!='null')].iloc[0].processed_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b563ad6-56c5-4285-b308-53c67f8b85c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_core_cp[(df_core_cp.repo_name==\"cores\") & (df_core_cp.processed_methods!='null')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4dfa8-0199-48db-8512-506ffff35e15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_core_cp[df_core_cp.methods!='null'].iloc[0].processed_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f3c0e-bc62-4979-bede-9da0f608fc52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_core_resolved[df_core_resolved.methods!='null'].iloc[0].methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d6b8b-f343-48a3-9491-5a13e01bf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_methods_all_core = get_all_core_method_dict_from_repo(df_core_resolved, is_resolved=True)\n",
    "# class_to_methods_all_core = {key: val for key, val in class_to_methods_all_core.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c79c4-f557-4be4-a9fa-68dd5b1dfe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_resolved = resolve_inheritance(df_cp, class_to_methods_all_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960a384-f442-415f-bd64-44e189435dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resolved.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc599dc2-5046-45bf-ae7c-94c7aa2e3fb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# filter df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ad419-7161-43f5-a2e0-166af68a5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_resolved[~(df_resolved.methods=='null') | ~(df_resolved.methods=='null')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482dca1-bffb-445b-8392-6105093bfb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered), df_filtered.repo_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186df1e5-f94f-4d36-abec-4e9fa9212373",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_constructor_perfname(df):\n",
    "    df_cp = df.copy()\n",
    "    df_list = []\n",
    "    for id_, library, path, code, methods, methods_exp, constructors, fname in df_cp.values:\n",
    "        constructors = constructors.split(\" \")\n",
    "        for constructor in constructors:\n",
    "            temp_methods = methods.get(constructor, set())\n",
    "            df_list.append(\n",
    "                {\n",
    "                    'id': id_,\n",
    "                    'library': library,\n",
    "                    'path': path,\n",
    "                    # 'code': code,\n",
    "                    'methods': \"###\".join(list(temp_methods)),\n",
    "                    'len_methods': len(temp_methods),\n",
    "                    'constructor': constructor,\n",
    "                    'fname': fname\n",
    "                }\n",
    "            )\n",
    "    df_out = pd.DataFrame(df_list)\n",
    "    df_out = df_out[df_out.len_methods > 0].copy()\n",
    "    df_out.drop(columns='len_methods', inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630a65a-48a0-4f32-bf0a-1eb9cbf666b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = extract_constructor_perfname(df_filtered)\n",
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7033356-8239-46e5-8469-d4dbb013a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.drop_duplicates(inplace=True)\n",
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efc710-59fe-48fb-9259-6c95170133ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45546f-63bf-4c16-8aac-59fbefce5a81",
   "metadata": {},
   "source": [
    "# get valid include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c24b6d-dc71-4d12-a887-97b786b165db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_appfile(cpp_file):\n",
    "    cpp_file = re.sub(r\"(/\\*.+?(?=\\*/)\\*/)\", \"\", cpp_file, flags=re.DOTALL)\n",
    "    cpp_file = re.sub(r\"(//.+?\\n)\", r\"\\n\", cpp_file, flags=re.DOTALL)\n",
    "    # cpp_file = re.sub(r\"(#.*?\\n)|(#(endif|else))\", r\"\\n\", cpp_file)\n",
    "    cpp_file = cpp_file.split('\\n')\n",
    "    cpp_file = [x.strip() for x in cpp_file if x.strip() != '']\n",
    "    cpp_file = '\\n'.join(cpp_file)\n",
    "    return cpp_file\n",
    "\n",
    "def get_ino_files(path):\n",
    "    dir_list = os.listdir(path)\n",
    "    \n",
    "    codes = []\n",
    "    for id_ in dir_list:\n",
    "        temp_path = os.path.join(path, id_)\n",
    "        \n",
    "        for root, dirnames, filenames in os.walk(temp_path):\n",
    "            \n",
    "            for name in filenames:    \n",
    "                if name.endswith(\".ino\"):\n",
    "                    filepath = os.path.join(root, name)\n",
    "                    library = root.split(\"/\")[3]\n",
    "                    with open(filepath, 'r', errors='ignore') as f:\n",
    "                        code = f.read()\n",
    "                    code = preprocess_appfile(code)\n",
    "                    codes.append({\n",
    "                        'id': id_,\n",
    "                        'library': library,\n",
    "                        'path': filepath,\n",
    "                        'code': code,\n",
    "                    })\n",
    "    df = pd.DataFrame(codes)\n",
    "    return df\n",
    "\n",
    "def get_h_files(path):\n",
    "    dir_list = os.listdir(path)   \n",
    "    codes = []\n",
    "    for id_ in dir_list:\n",
    "        temp_path = os.path.join(path, id_)\n",
    "        \n",
    "        for root, dirnames, filenames in os.walk(temp_path):\n",
    "            \n",
    "            for name in filenames:    \n",
    "                if name.endswith(\".h\"):\n",
    "                    filepath = os.path.join(root, name)\n",
    "                    library = root.split(\"/\")[3]\n",
    "                    with open(filepath, 'r', errors='ignore') as f:\n",
    "                        code = f.read()\n",
    "                    code = preprocess_appfile(code)\n",
    "                    codes.append({\n",
    "                        'id': id_,\n",
    "                        'library': library,\n",
    "                        'path': filepath,\n",
    "                        'code': code,\n",
    "                    })\n",
    "    df = pd.DataFrame(codes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea9eb0-0b55-4bd3-88af-c2206c53592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino = get_ino_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdec3e4-cb6e-4695-a488-37023fa1287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ec2cc-d5f7-4549-8c2d-66b31b6bb614",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "declarator = ['init_declarator', \n",
    "              'function_declarator']\n",
    "\n",
    "val_list = ['argument_list', \n",
    "            'parameter_list', \n",
    "            'initializer_list']\n",
    "\n",
    "# 'unsigned', 'signed', 'long', 'short' == sized_type_identifier\n",
    "type_list = ['primitive_type', \n",
    "             'type_identifier', \n",
    "             'sized_type_specifier']\n",
    "\n",
    "sized_type_specifier_list = ['unsigned', \n",
    "                             'signed', \n",
    "                             'long', \n",
    "                             'short']\n",
    "\n",
    "expression_list = ['conditional_expression',\n",
    "                   'assignment_expression',\n",
    "                   'binary_expression',\n",
    "                   'unary_expression',\n",
    "                   'cast_expression',\n",
    "                   'pointer_expression',\n",
    "                   'sizeof_expression',\n",
    "                   'subscript_expression',\n",
    "                   'call_expression',\n",
    "                   'field_expression',\n",
    "                   'compound_literal_expression',\n",
    "                   'string_literal',\n",
    "                   'number_literal',\n",
    "                   'char_literal',\n",
    "                   'true',\n",
    "                   'false',\n",
    "                   'null',\n",
    "                   'concatenated_string',\n",
    "                   'parenthesized_expression']\n",
    "\n",
    "for_expression = ['conditional_expression',\n",
    "                   'assignment_expression',\n",
    "                   'binary_expression',\n",
    "                   'unary_expression',\n",
    "                   'cast_expression',\n",
    "                   'pointer_expression',\n",
    "                   'sizeof_expression',\n",
    "                   'subscript_expression',\n",
    "                   'call_expression',\n",
    "                   'field_expression',\n",
    "                   'parenthesized_expression']\n",
    "\n",
    "exclusion_list = val_list + expression_list\n",
    "\n",
    "built_in_api = [\"digitalRead\", \n",
    "                \"digitalWrite\", \n",
    "                'analogRead', \n",
    "                'analogWrite', \n",
    "                'noTone', \n",
    "                'tone', \n",
    "                'pulseIn', \n",
    "                'pulseInLong', \n",
    "                'shiftIn', \n",
    "                'shiftOut', \n",
    "                'analogWrite', \n",
    "                'analogReadResolution', \n",
    "                'analogWriteResolution',\n",
    "                'attachInterrupt', \n",
    "                'detachInterrupt']\n",
    "\n",
    "exclusion_lib = ['SPI', \n",
    "                 'Wire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90694a4-db95-413d-b960-8ac5c9f78ef6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_declarations(code):\n",
    "    declaration_list = []\n",
    "    declaration_dict = {}\n",
    "    includes = []\n",
    "    constant_dict = {}\n",
    "    \n",
    "    code_splitted = code.split(\"\\n\")\n",
    "    \n",
    "    query = CP_LANGUAGE.query(\"\"\"\n",
    "    ((preproc_include) @libname)\n",
    "    (translation_unit (declaration) @declaration_pattern1)\n",
    "    (translation_unit (preproc_ifdef (declaration) @declaration_pattern2))\n",
    "    \"\"\")\n",
    "    \n",
    "    tree = parser.parse(bytes(code, \"utf8\"))\n",
    "    query_results = query.captures(tree.root_node)\n",
    "    translator = str.maketrans('', '', '<>\"\\'')            \n",
    "    \n",
    "    for node, node_type in query_results:\n",
    "        if node_type in ('libname'):\n",
    "            for element, path in traverse_tree_with_path(node):\n",
    "                temp1, temp2 = get_node_name(node=element, loc_list=code_splitted)\n",
    "            \n",
    "                if path[-1] == 'system_lib_string':\n",
    "                    includes.append(temp2.translate(translator).split(\".\")[0])\n",
    "                \n",
    "                elif path[-1] == 'string_literal':\n",
    "                    temp2 = resolve_string_literal(node=element, loc_list=code_splitted)\n",
    "                    includes.append(temp2.translate(translator).split(\".\")[0])\n",
    "            \n",
    "        if node_type in ('declaration_pattern1', 'declaration_pattern2'):\n",
    "            declaration = get_substring(node=node, loc_list=code_splitted)\n",
    "            item_dict = {'type': 'init',\n",
    "                        'statement': declaration, \n",
    "                        'obj_type_identifier': [],\n",
    "                        'obj_name': None,\n",
    "                        'identifiers': [],}\n",
    "            is_const = False\n",
    "            temp_identifier = ''\n",
    "            \n",
    "            for element, path in traverse_tree_with_path(node):\n",
    "                temp1, temp2 = get_node_name(node=element, loc_list=code_splitted)\n",
    "                intersection = set(path) & set(exclusion_list)\n",
    "                \n",
    "                if path[-1] == 'identifier':                \n",
    "                    if len(intersection) == 0 and not item_dict['obj_name']:\n",
    "                        item_dict['obj_name'] = temp2\n",
    "                    else:\n",
    "                        item_dict['identifiers'].append(temp2)\n",
    "                \n",
    "                elif path[-1] == 'init_declarator':\n",
    "                    item_dict['type'] = 'init_declarator'\n",
    "                \n",
    "                elif path[-1] == 'type_identifier':\n",
    "                    item_dict['obj_type_identifier'].append(temp2)\n",
    "                \n",
    "                elif path[-1] == 'const':\n",
    "                    is_const = True\n",
    "                    \n",
    "                if item_dict.get('type', '') == 'init_declarator' and path[-2] == 'init_declarator' and path[-1] != '=':\n",
    "                    \n",
    "                    if path[-1] == 'identifier' and temp_identifier == '':\n",
    "                        temp_identifier = temp2\n",
    "                        \n",
    "                    else:\n",
    "                        temp_str = get_substring(node=element, loc_list=code_splitted) \n",
    "                        \n",
    "                        if is_const == True:\n",
    "                            constant_dict[temp_identifier] = temp_str\n",
    "                        else:\n",
    "                            declaration_dict[temp_identifier] = temp_str\n",
    "                        \n",
    "                        is_const = False\n",
    "                        temp_identifier = ''\n",
    "            \n",
    "            declaration_list.append(item_dict)\n",
    "    \n",
    "    declaration_list = [subitem for item in declaration_list for subitem in item['obj_type_identifier'] if len(item['obj_type_identifier']) > 0]\n",
    "    \n",
    "    return declaration_list, includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2caff0-5076-43a2-b29b-650a202b641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino['temp'] = df_ino.code.progress_apply(lambda x: get_declarations(x))\n",
    "df_ino['declarations'] = df_ino.temp.progress_apply(lambda x: x[0])\n",
    "# df_ino['declarations'] = df_ino.code.progress_apply(lambda x: get_declarations(x))\n",
    "df_ino[\"n_declarations\"] = df_ino.declarations.progress_apply(lambda x: len(x))\n",
    "df_ino['includes'] = df_ino.temp.progress_apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e77c8-2e4e-48a6-8b16-30719de58e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino_filtered = df_ino[df_ino.n_declarations > 0].copy()\n",
    "len(df_ino), len(df_ino_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86faf4e1-107a-41bc-b2a5-185029319a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ino_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bec968-ea80-4a8c-8816-5687d596a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38405c-bdf2-4f59-9432-e8b92c74c4f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_constructor(x, df_ino):\n",
    "    df_ino_cp = df_ino.copy()\n",
    "    id_ = x.id\n",
    "    \n",
    "    df_ino_cp = df_ino_cp[df_ino_cp.id == id_]\n",
    "    if len(df_ino_cp) > 0:\n",
    "        declarations = df_ino_cp.declarations.tolist()\n",
    "        declarations = [subitem for item in declarations for subitem in item]\n",
    "        \n",
    "        includes = df_ino_cp.includes.tolist()\n",
    "        includes = [subitem for item in includes for subitem in item]\n",
    "        \n",
    "        constructor = x.constructor\n",
    "        fname = x.fname\n",
    "\n",
    "        if constructor in declarations :\n",
    "            return 'constructor'\n",
    "        \n",
    "        # elif fname in includes:\n",
    "        #     return 'fname'\n",
    "        \n",
    "        else:\n",
    "            return 'null'\n",
    "    \n",
    "    else:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a44b0a-f823-4be5-a937-3e912c801b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['is_pass'] = df_filtered.progress_apply(lambda x: check_constructor(x, df_ino_filtered), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28d691-6b04-4b42-b443-0500d9a164be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.is_pass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f654678-ae1f-4f16-a0a6-a3ca7778a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered[df_filtered.is_pass!='null'].copy()\n",
    "df_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4c0d4-aa25-4533-bc38-a3d0ff0d7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.drop(columns=['is_pass', 'fname', 'path'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41107d2c-4a32-4866-ad29-0d14a620258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"db_libraries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7e92f-df93-440a-a4d9-ca2099fe7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65b7d2-8f8b-4700-9bf4-67229188b81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
