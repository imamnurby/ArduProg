{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bbde5-3bbe-49b8-9689-07372850b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23bf419-8d77-441e-8d95-c168536140d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053711c7-d7f7-4334-b9f2-fa57a1860790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a034d-730c-4ebd-98dc-3ad53af9eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate import meteor\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08e5e3-db7e-4464-80f0-9cef9bef9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2664e-860f-49c8-a3ac-4c3b61353d94",
   "metadata": {},
   "source": [
    "# open result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd395a-66d2-415f-94c4-3dae9089dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = \"output_inference/deep_api_all_100/results_computed.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d6de8-d3e6-4398-8ef9-ca5c11e0f5df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(RESULT_PATH, 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a14ace-43cc-4592-8125-2a0f8bb8bff1",
   "metadata": {},
   "source": [
    "# compute largest common subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c357134-51b1-454e-a7cd-9097a5dd51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "def calculate_rouge(prediction, ground_truth):\n",
    "    scores = rouge.get_scores(prediction, ground_truth)\n",
    "    return scores\n",
    "\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "def calculate_bleu(prediction, ground_truth):\n",
    "    prediction = prediction.split()\n",
    "    score = sentence_bleu([ground_truth], prediction, smoothing_function=chencherry.method1, weights=(1, 0))\n",
    "    return score\n",
    "\n",
    "def calculate_meteor(prediction, ground_truth):\n",
    "    prediction = prediction.split()\n",
    "    meteor_score = round(meteor([ground_truth],prediction), 4)\n",
    "    return meteor_score\n",
    "\n",
    "def get_n_common_elements(result_dict):\n",
    "    result_dict_cp = copy.deepcopy(result_dict)\n",
    "    \n",
    "    ground_truth = result_dict_cp.get('ground_truth', [])\n",
    "    assert(len(ground_truth) > 0)\n",
    "    \n",
    "    preds = result_dict_cp.get('preds', [])\n",
    "    preds = [pred for pred in preds if pred != '']\n",
    "    assert(len(preds) > 0)\n",
    "    \n",
    "    n_common_elements = []\n",
    "    \n",
    "    for pred in preds:\n",
    "        pred = pred.split()\n",
    "        common_elements = set(ground_truth) & set(pred)\n",
    "        n_common_elements.append(len(common_elements))\n",
    "    \n",
    "    return n_common_elements\n",
    "\n",
    "def compute_score(result_dict, score_type=\"rouge\"):\n",
    "    result_dict_cp = copy.deepcopy(result_dict)\n",
    "    \n",
    "    ground_truth = result_dict_cp.get('ground_truth', [])\n",
    "    assert(len(ground_truth) > 0)\n",
    "    \n",
    "    preds = result_dict_cp.get('preds', [])\n",
    "    preds = [pred for pred in preds if pred != '']\n",
    "    assert(len(preds) > 0)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for pred in preds:\n",
    "        if score_type == \"rouge\":\n",
    "            score = calculate_rouge(pred, ' '.join(ground_truth))\n",
    "            # scores.append(score[0]['rouge-l']['f'])\n",
    "            scores.append(score[0]['rouge-1']['r'])\n",
    "        \n",
    "        elif score_type == \"bleu\":\n",
    "            score = calculate_bleu(pred, ground_truth)\n",
    "            scores.append(score)\n",
    "        \n",
    "        elif score_type == \"meteor\":\n",
    "            score = calculate_meteor(pred, ground_truth)\n",
    "            scores.append(score)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid score type\")\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5fed8-3cce-4511-978c-f6dfeaf7eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_common_elements = get_n_common_elements(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916eb6c-8b3f-4403-ae9f-50a453e1d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevancy_scores(n_common_elements, len_ground_truth):\n",
    "    return [n/len_ground_truth for n in n_common_elements]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af6bcd-34a9-42ff-acec-c850c11db9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_relevancy_scores = compute_relevancy_scores(test_n_common_elements, len(results[0].get('ground_truth')))\n",
    "test_relevancy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e35400-9b69-4802-acc5-200c9f87c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b295cd8-29d1-4c30-bc24-5bca6db9ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_dcg(relevancy_scores):\n",
    "#     dcg = []\n",
    "#     for idx, val in enumerate(relevancy_scores): \n",
    "#         # relevance score\n",
    "#         numerator = math.pow(2, val)-1\n",
    "#         # numerator = val\n",
    "#         # add 2 because python 0-index\n",
    "#         denominator =  np.log2(idx + 2) \n",
    "#         score = numerator/denominator\n",
    "#         dcg.append(score)\n",
    "#     return sum(dcg)\n",
    "def compute_dcg(relevance, alternate=True):\n",
    "    if relevance is None or len(relevance) < 1:\n",
    "        return 0.0\n",
    "\n",
    "    rel = np.asarray(relevance)\n",
    "    p = len(rel)\n",
    "\n",
    "    if alternate:\n",
    "        # from wikipedia: \"An alternative formulation of\n",
    "        # DCG[5] places stronger emphasis on retrieving relevant documents\"\n",
    "\n",
    "        log2i = np.log2(np.asarray(range(1, p + 1)) + 1)\n",
    "        return ((np.power(2, rel) - 1) / log2i).sum()\n",
    "    else:\n",
    "        log2i = np.log2(range(2, p + 1))\n",
    "        return rel[0] + (rel[1:] / log2i).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfa07f-d2ea-49bf-a8e4-1ab37ae91341",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dcg(test_relevancy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f47d38-5fa8-4a44-8c7a-c9703c87a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dcg([3,2,3,0,1,2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416219f-3e86-4e5d-a459-751d8b5f4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_length(a, b):\n",
    "    table = [[0] * (len(b) + 1) for _ in range(len(a) + 1)]\n",
    "    for i, ca in enumerate(a, 1):\n",
    "        for j, cb in enumerate(b, 1):\n",
    "            table[i][j] = (\n",
    "                table[i - 1][j - 1] + 1 if ca == cb else\n",
    "                max(table[i][j - 1], table[i - 1][j]))\n",
    "    return table[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab008325-1d48-45e4-b75e-e52cc2259393",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]['ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735410cc-f664-471e-940d-cabc53f74df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]['preds'][1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee4895-3469-4bf6-8d00-b9c0ee20cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs_length(results[0]['ground_truth'], results[0]['preds'][-1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b92033-77f2-4758-9630-4746f9d72cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_subseq(result_dict):\n",
    "    result_dict_cp = copy.deepcopy(result_dict)\n",
    "    \n",
    "    ground_truth = result_dict_cp.get('ground_truth', [])\n",
    "    assert(len(ground_truth) > 0)\n",
    "    \n",
    "    preds = result_dict_cp.get('preds', [])\n",
    "    preds = [pred for pred in preds if pred != '']\n",
    "    assert(len(preds) > 0)\n",
    "    \n",
    "    n_common_subseq = []\n",
    "    \n",
    "    for pred in preds:\n",
    "        pred = pred.split()\n",
    "        common_subseq = lcs_length(pred, ground_truth)\n",
    "        n_common_subseq.append(common_subseq)\n",
    "    \n",
    "    return n_common_subseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e55bc1-1ce3-4483-9a5c-e949ede3e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_relevancy_scores(get_common_subseq(results[1]), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd8e0b-edc6-42e9-8bc4-64ac8fa1c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dcg(compute_relevancy_scores(get_common_subseq(results[1]), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abe404-e1ab-4f2b-8854-14cb897df615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(results, topk, score_type):\n",
    "    ndcg_list = []\n",
    "    for result_dict in results:\n",
    "        len_ground_truth = len(result_dict.get('ground_truth', []))\n",
    "        assert(len_ground_truth>0)\n",
    "        \n",
    "        ideal_scores = [1 for x in range(topk)]\n",
    "        if score_type == \"common-intersection\":\n",
    "            n_common_elements = get_n_common_elements(result_dict)[:topk].copy()\n",
    "            relevancy_scores = compute_relevancy_scores(n_common_elements, len_ground_truth)\n",
    "            dcg_score = compute_dcg(relevancy_scores)\n",
    "            \n",
    "        elif score_type == \"common-subsequence\":\n",
    "            n_common_elements = get_common_subseq(result_dict)[:topk].copy()\n",
    "            relevancy_scores = compute_relevancy_scores(n_common_elements, len_ground_truth)\n",
    "            dcg_score = compute_dcg(relevancy_scores)\n",
    "            \n",
    "        \n",
    "        elif score_type in (\"rouge\", \"bleu\", \"meteor\"):\n",
    "            relevancy_scores = compute_score(result_dict, score_type=score_type)[:topk].copy()\n",
    "            dcg_score = compute_dcg(relevancy_scores)\n",
    "        \n",
    "        idcg_score = compute_dcg(ideal_scores)\n",
    "        ndcg_scores = dcg_score/idcg_score\n",
    "        ndcg_list.append(ndcg_scores)\n",
    "        \n",
    "    return sum(ndcg_list)/len(ndcg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2f9a8-fd4b-43d0-85f0-28feb1929198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_topk(results, topk_list, score_type):\n",
    "    ndcg_dict = {}\n",
    "    for k in topk_list:\n",
    "        average_dcg = ndcg(results, k, score_type)\n",
    "        ndcg_dict[k] = round(average_dcg, 3)\n",
    "    return ndcg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dfe084-6300-4824-b6ea-102f76cc59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_list = [1, 5, 10]\n",
    "ndcg_topk(results, topk_list, \"common-subsequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2996d6-5fbc-4a8c-9597-d81c9f15738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_list = [1, 5, 10]\n",
    "ndcg_topk(results, topk_list, \"bleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4e12b-2789-49d9-b7d3-a765546e123d",
   "metadata": {},
   "source": [
    "# compute for all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1aefe8-cd8a-4646-8c99-8390e899e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(dcg_dict):\n",
    "    for model, score_types in dcg_dict.items():\n",
    "        print(model)\n",
    "        for score_type, dcg_scores in score_types.items():\n",
    "            print(score_type)\n",
    "            print(\"-------\"*5)\n",
    "            for k, score in dcg_scores.items():\n",
    "                print(f\"{k}_{score_type}:{score}\")\n",
    "            print()\n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91840a73-4028-40a8-810d-5b1086f10b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_path = {\n",
    "    'deep_api': 'output_inference/deep_api_all_100/results_ndcg.json',\n",
    "    'codebert': 'output_inference/codebert2codebert_all_100/results_ndcg.json',\n",
    "    'codet5': 'output_inference/codet5_all_100/results_ndcg.json',\n",
    "    'plbart': 'output_inference/plbart_all_100/results_ndcg.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5f8b7-cedf-4014-a5e6-09b27906bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_dict = {}\n",
    "topk = (1, 5, 10)\n",
    "score_types = (\"rouge\", \"bleu\", \"meteor\", \"common-subsequence\")\n",
    "\n",
    "for score_type in score_types:\n",
    "    for model, path in model_to_path.items():\n",
    "        \n",
    "        if model not in ndcg_dict:\n",
    "            ndcg_dict[model] = {}\n",
    "        \n",
    "        with open(path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "\n",
    "        ndcg_dict[model][score_type] = ndcg_topk(results, topk, score_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ff578-e1ae-4192-8a44-6ac45bdb585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(ndcg_dict):\n",
    "    models = []\n",
    "    top1_scores = []\n",
    "    top5_scores = []\n",
    "    top10_scores = []\n",
    "    types_ = []\n",
    "    \n",
    "    for model, score_types in ndcg_dict.items():\n",
    "        for score_type, dcg_scores in score_types.items():\n",
    "            top1_scores.append(dcg_scores[1])\n",
    "            top5_scores.append(dcg_scores[5])\n",
    "            top10_scores.append(dcg_scores[10])\n",
    "            models.append(model)\n",
    "            types_.append(score_type)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'model': models,\n",
    "        'score_type': types_,\n",
    "        'k_1': top1_scores,\n",
    "        'k_5': top5_scores,\n",
    "        'k_10': top10_scores\n",
    "    })\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729605a-a22a-4266-9b65-c8bd2af2a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_df(ndcg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398d811-2506-4849-8319-f3f3f6344ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results_ndcg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d6ff5-d0a0-4238-879e-c4072e97c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4363c-4c95-4e94-ab9b-7695d2727988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
